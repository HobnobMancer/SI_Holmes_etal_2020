{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary Information: Holmes *et al.* 2017\n",
    "\n",
    "# 3. An unpooled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pystan\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "\n",
    "import tools\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_context('notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "\n",
    "With this unpooled model, we treat each probe across both *treatment* conditions as if the measured *output* intensity is a linear function, with a common *input* vs. *output* intensity offset $\\alpha$ for all probes, but a probe-specific slope $\\beta_{j[i]}$. This slope represents - only for the *probe ID* $j[i]$ - effect of conducting the experiment on how the *output* intensity relates to the *input* intensity. It is, in this process, our first step towards determining a gene-wise effect of the experiment on relative proportions of the gene in pre- and post-experiment BAC pools.\n",
    "\n",
    "We distinguish between *probe* (a spot on an array) and *probe ID* (the unifying common identifier of probes across several arrays). When we consider a *probe ID* we are considering a gene-level effect, not a probe-level effect.\n",
    "\n",
    "We construct the following model of the experiment:\n",
    "\n",
    "$$y_i = \\alpha + \\beta_{j[i]} x_i + \\epsilon_i$$\n",
    "\n",
    "* $y_i$: measured intensity output on the array for probe $i$ (specific to each replicate)\n",
    "* $x_i$: measured intensity input on the array for probe $i$ (specific to each replicate)\n",
    "* $\\alpha$: the linear intercept, this is a constant 'offset' for all *output* measurements relative to *input* measurements\n",
    "* $\\beta_{j[i]}$: the linear slope, this is the relative change in measured intensity between *input* and *output* intensities *at the probe ID level* - it differs for each *probe ID*\n",
    "* $\\epsilon_i$: error in the model prediction for probe $i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stan model construction and fit\n",
    "\n",
    "We need to define `data`, `parameters` and our `model` for `Stan`.\n",
    "\n",
    "In the `data` block, we have:\n",
    "\n",
    "* `N`: `int`, the number of data points)\n",
    "* `J`: `int`, the number of unique probe IDs (`J` < `N`)\n",
    "* `probe`: `int[N]`, an index list of probe identities - one index representing six probe measurements (i.e. three control, three treatment) - there are `J` probes\n",
    "* `x`: `vector[N]`, the input log(intensity) values\n",
    "* `y`: `vector[N]`, the output log(intensity) values\n",
    "\n",
    "In the `parameter` block, we have:\n",
    "\n",
    "* `a`: `real`, representative input log(intensity)\n",
    "* `b`: `real vector[J]`, effect on log(intensity) of passing through the experiment, specific to a probe ID\n",
    "* `sigma`: `real<lower=0>`, the error in the prediction\n",
    "\n",
    "We also define a `transformed parameter`:\n",
    "\n",
    "* `y_hat[i] <- b[probe[i]] * x[i] + a`: the linear relationship describing $\\hat{y}$, our estimate of experimental output intensity, which is subject to variance `sigma`.\n",
    "\n",
    "We define the model as $y \\sim N(\\hat{y}, \\sigma^2)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We map Python variables to `stan` variables, so we need to load our cleaned, normalised dataset, and create an index for each probe ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load clean, normalised data\n",
    "# data = pd.read_csv(\"output/normalised_array_data.tab\", sep=\"\\t\")  # full dataset\n",
    "data = pd.read_csv(\"output/reduced_normalised_indexed_array_data.tab\", sep=\"\\t\")  # reduced dataset for test\n",
    "\n",
    "# useful values\n",
    "probe_ids = data['probe'].unique()\n",
    "nprobes = len(probe_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define unpooled stan model\n",
    "unpooled_model = \"\"\"\n",
    "data {\n",
    "  int<lower=0> N;\n",
    "  int<lower=0> J;\n",
    "  int<lower=1, upper=J> probe[N];\n",
    "  vector[N] x;\n",
    "  vector[N] y;\n",
    "}\n",
    "parameters {\n",
    "  real a;\n",
    "  vector[J] b;\n",
    "  real<lower=0> sigma;\n",
    "}\n",
    "transformed parameters{\n",
    "  vector[N] y_hat;\n",
    "\n",
    "  for (i in 1:N)\n",
    "    y_hat[i] = a + b[probe[i]] * x[i];\n",
    "}\n",
    "model {\n",
    "  y ~ normal(y_hat, sigma);\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# relate python variables to stan variables\n",
    "unpooled_data_dict = {'N': len(data),\n",
    "                      'J': nprobes,\n",
    "                      'probe': data['probe_index'] + 1,\n",
    "                      'x': data['input'],\n",
    "                      'y': data['output']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run stan fit\n",
    "unpooled_fit = pystan.stan(model_code=unpooled_model,\n",
    "                           data=unpooled_data_dict,\n",
    "                           iter=1000, chains=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the fit\n",
    "\n",
    "We cannot inspect the fitted parameter estimates quite so straightforwardly, as there are (for the full dataset) now approximately 11000 parameters describing the slope for individual probe IDs, $\\beta_j[i]$. We can, however, get an estimate of the range of values those slopes and look at the potential for outliers - specific probe IDs that look as though they may deviate quite far from the mean of all estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot estimates for alpha (intercept)\n",
    "tools.plot_fit_params(unpooled_fit, ['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(tools.print_intervals(unpooled_fit, 'a', 95))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the reduced test data set, we now find we have quite a different intercept ($\\bar{\\alpha} \\approx 79$), with a much broader range of estimates that span zero and sometimes take negative values.\n",
    "\n",
    "Modifying the structure of the model has greatly modified our estimate of a \"common intercept\", and the wide range of values, combined with a potential for type S error, should suggest that we still need to refine it further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get fits of beta by probe ID\n",
    "unpooled_estimates = pd.Series(unpooled_fit['b'].mean(0), index=probe_ids)\n",
    "unpooled_se = pd.Series(unpooled_fit['b'].std(0), index=probe_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Inspect the estimates\n",
    "unpooled_estimates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot distribution\n",
    "g = sns.boxplot(unpooled_estimates)\n",
    "g.set_title(\"Distribution of mean slope for unpooled model\")\n",
    "g.set_xlabel(\"mean(beta)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the boxplot we can see that the distribution of mean inferred values of $\\beta$ (by probe ID) is very tight, and they lie mostly close to zero. There are quite a few negative outlying values, and fewer positive outliers.\n",
    "\n",
    "We are primarily interested in the outlying values of $\\beta$, as these represent strong inferred effects on gene recovery after conducting the experiment (strong effects on *output* measurement, with respect to the *input* measurement). Negative values may be associated with genes that are deleterious in the experiment, positive values genes that are preferentially retained and provide an advantage in the experimental context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot standard errors\n",
    "g = sns.boxplot(unpooled_se)\n",
    "g.set_title(\"Distribution of standard error for unpooled model\")\n",
    "g.set_xlabel(\"se(beta)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated values of $\\beta$ are just estimates, but we can also get an idea of the certainty we have in the estimate by looking at the standard error of $\\beta$. Where this is close to zero, we can be confident in our estimate of the parameter under this model. Where it is large - perhaps larger than the value of $\\beta$ itself - we should treat the estimate with caution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How does estimate of error relate to error in the estimate\n",
    "plt.scatter(unpooled_estimates, unpooled_se, alpha=0.2)\n",
    "plt.title(\"Relationship between mean(beta) and se(beta)\")\n",
    "plt.xlabel(\"mean(beta)\")\n",
    "plt.ylabel(\"se(beta)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plot we can see that thre appears to be a relationship such that the more variable estimates of $\\beta$ are also the larger estimates of $\\beta$. This could occur for a number of reasons.\n",
    "\n",
    "* the error in $\\beta$ may just be proportional to $|\\beta|$ - but the bulk of estimates appear to have $0 < \\beta < 2$ with a standard error of close to zero, which would seem to contradict that\n",
    "* the genes that are strongly advantageous or deleterious may only show that effect in the experiments where *treatment* is applied: the exact effect we want to see! \n",
    "* the pooled estimate of $\\alpha$ is a negative effect on our ability to fit these larger $\\beta$ values\n",
    "\n",
    "This result is possibly an encouraging sign that we are closing in on the effect we want to identify, but we will need to modify the model structure to see this directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot error in estimate of beta for larger positive values\n",
    "tools.plot_threshold_errors(unpooled_estimates, unpooled_se, 1, upper=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot error in estimate of beta for larger negative values\n",
    "tools.plot_threshold_errors(unpooled_estimates, unpooled_se, 0, upper=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both positive and negative large values, we can confirm that the largest values tend to have relatively large uncertainty in their estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we are still not capturing information important for our central question:\n",
    "\n",
    "* we are combining experiments with and without passage\n",
    "* we are assuming a pooled intercept (the same base level of expression for all probes)\n",
    "* whether probes that hybridise to Sakai have a different signal\n",
    "* we are not incorporating any pertinent biological information (e.g. hierarchy of operons/regulons)\n",
    "\n",
    "and it is possible that by extending our model we can reduce the variability we see in these estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

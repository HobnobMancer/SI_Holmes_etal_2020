{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary Information: Holmes *et al.* 2017\n",
    "\n",
    "# 4. Varying base expression level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pystan\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "\n",
    "import tools\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_context('notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "\n",
    "In our first unpooled model, we treated each probe as if there were an effect relating the measured *output* intensity to the *input* intensity for that probe, specific to the probe ID.  We treated that output value as some linear function of the input value, where the intercept $\\alpha$ as though was a single pooled value for all probes. Here, we'll change that assumption so that we consider each probe to have an intercept that is specific to its *probe ID*.\n",
    "\n",
    "This is in effect equivalent to fitting a different linear model to each *probe ID*.\n",
    "\n",
    "We construct the following model of the experiment:\n",
    "\n",
    "$$y_i = \\alpha_{j[i]} + \\beta_{j[i]} x_i + \\epsilon_i$$\n",
    "\n",
    "* $y_i$: measured intensity output on the array for probe $i$ (specific to each replicate)\n",
    "* $x_i$: measured intensity input on the array for probe $i$ (specific to each replicate)\n",
    "* $\\alpha_{j[i]}$: the linear intercept, this is a constant 'offset' for all *output* measurements relative to *input* measurements, but it differs for each *probe ID*\n",
    "* $\\beta_{j[i]}$: the linear slope, this is the relative change in measured intensity between *input* and *output* intensities *at the probe ID level* - it differs for each *probe ID*\n",
    "* $\\epsilon_i$: error in the model prediction for probe $i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stan model construction and fit\n",
    "\n",
    "We need to define `data`, `parameters` and our `model` for `Stan`.\n",
    "\n",
    "In the `data` block, we have:\n",
    "\n",
    "* `N`: `int`, the number of data points)\n",
    "* `J`: `int`, the number of unique probe IDs (`J` < `N`)\n",
    "* `probe`: `int[N]`, an index list of probe identities - one index representing six probe measurements (i.e. three control, three treatment) - there are `J` probes\n",
    "* `x`: `vector[N]`, the input log(intensity) values\n",
    "* `y`: `vector[N]`, the output log(intensity) values\n",
    "\n",
    "In the `parameter` block, we have:\n",
    "\n",
    "* `a`: `real vector[J]`, representative input log(intensity)\n",
    "* `b`: `real vector[J]`, effect on log(intensity) of passing through the experiment, specific to a probe ID\n",
    "* `sigma`: `real<lower=0>`, the error in the prediction\n",
    "\n",
    "We also define a `transformed parameter`:\n",
    "\n",
    "* `y_hat[i] <- b[probe[i]] * x[i] + a[probe[i]]`: the linear relationship describing $\\hat{y}$, our estimate of experimental output intensity, which is subject to variance `sigma`.\n",
    "\n",
    "We define the model as $y \\sim N(\\hat{y}, \\sigma^2)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load clean, normalised, indexed data\n",
    "# data = pd.read_csv(\"output/normalised_array_data.tab\", sep=\"\\t\")  # full dataset\n",
    "data = pd.read_csv(\"output/reduced_normalised_indexed_array_data.tab\", sep=\"\\t\")  # reduced dataset for test\n",
    "\n",
    "# useful values\n",
    "probe_ids = data['probe'].unique()\n",
    "nprobes = len(probe_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define unpooled stan model\n",
    "unpooled_model = \"\"\"\n",
    "data {\n",
    "  int<lower=0> N;\n",
    "  int<lower=0> J;\n",
    "  int<lower=1, upper=J> probe[N];\n",
    "  vector[N] x;\n",
    "  vector[N] y;\n",
    "}\n",
    "parameters {\n",
    "  vector[J] a;\n",
    "  vector[J] b;\n",
    "  real<lower=0> sigma;\n",
    "}\n",
    "transformed parameters{\n",
    "  vector[N] y_hat;\n",
    "\n",
    "  for (i in 1:N)\n",
    "    y_hat[i] = a[probe[i]] + b[probe[i]] * x[i];\n",
    "}\n",
    "model {\n",
    "  y ~ normal(y_hat, sigma);\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# relate python variables to stan variables\n",
    "unpooled_data_dict = {'N': len(data),\n",
    "                      'J': nprobes,\n",
    "                      'probe': data['probe_index'] + 1,\n",
    "                      'x': data['input'],\n",
    "                      'y': data['output']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run stan fit\n",
    "unpooled_fit = pystan.stan(model_code=unpooled_model,\n",
    "                           data=unpooled_data_dict,\n",
    "                           iter=1000, chains=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the fit\n",
    "\n",
    "Now there are (for the full dataset) now approximately 22000 parameters describing the slope and intercept for individual probe IDs. This is unwieldy. We can still get an estimate of the range of values those slopes and look at the potential for outliers - specific probe IDs that look as though they may deviate quite far from the mean of all estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get fits to alpha and beta by probe ID\n",
    "alpha_estimates = pd.Series(unpooled_fit['a'].mean(0), index=probe_ids)\n",
    "alpha_se = pd.Series(unpooled_fit['a'].std(0), index=probe_ids)\n",
    "beta_estimates = pd.Series(unpooled_fit['b'].mean(0), index=probe_ids)\n",
    "beta_se = pd.Series(unpooled_fit['b'].std(0), index=probe_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Inspect the estimates\n",
    "alpha_estimates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Inspect the estimates\n",
    "beta_estimates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intercept $\\alpha_{j[i]}$\n",
    "\n",
    "Taking the intercept first, we can get an overview of the mean and standard error of $\\alpha$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot means distribution\n",
    "g = sns.boxplot(alpha_estimates)\n",
    "g.set_title(\"Distribution of mean intercept\")\n",
    "g.set_xlabel(\"mean(alpha)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot error distribution\n",
    "g = sns.boxplot(alpha_se)\n",
    "g.set_title(\"Distribution of errors\")\n",
    "g.set_xlabel(\"se(alpha)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean intercept values are all very small/close to zero, though generally positive, which is encouraging. The error in the estimate of intercept is, however, very large in all cases, and most of the time we seem not to be able to exclude the possibility that the true intercept is zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# errors for intercept outliers\n",
    "tools.plot_threshold_errors(alpha_estimates, alpha_se, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# errors for intercept outliers\n",
    "tools.plot_threshold_errors(alpha_estimates, alpha_se, -1, upper=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slopes $\\beta_{j[i]}$\n",
    "\n",
    "The variation of slopes $\\beta_{j[i]}$ by *probe ID* are the most interesting estimates, as they are indicative of the way *output* intensity measurements depend on *input* intensity measurements, and could help identify genes that are advantageous or disadvantageous in our experiment.\n",
    "\n",
    "In our previous fit, we saw several strongly negative values of $\\beta_{j[i]}$, and only a few positive coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot distribution\n",
    "g = sns.boxplot(beta_estimates)\n",
    "g.set_title(\"Distribution of mean slopes\")\n",
    "g.set_xlabel(\"mean(beta)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot distribution\n",
    "g = sns.boxplot(beta_se)\n",
    "g.set_title(\"Distribution of mean slope error\")\n",
    "g.set_xscale(\"log\")\n",
    "g.set_xlabel(\"se(beta)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot all errors/means\n",
    "tools.plot_threshold_errors(beta_estimates, beta_se, -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How does estimate of error relate to error in the estimate\n",
    "plt.scatter(beta_estimates, beta_se, alpha=0.2)\n",
    "plt.title(\"Relationship between mean(beta) and se(beta)\")\n",
    "plt.xlabel(\"mean(beta)\")\n",
    "plt.ylabel(\"se(beta)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with estimates for the intercepts $\\alpha_{j[i]}$, we see that errors are typically small, and on the order of the size of the estimate for the mean, or smaller. \n",
    "\n",
    "The most variable estimates tend to also be the extreme estimates of the mean, though the effect is not so clear as for our model with a constant pooled $\\alpha$. All that has changed is that we now fit a *probe ID*-specific intercept - and the distribution of variable $\\alpha_{j[i]}$ has now become less strongly related to the corresponding mean, suggesting that we have removed a specific biasing effect.\n",
    "\n",
    "This is again potentially encouraging, if this variability is in fact due to an additional effect - that of the presence or absence of the treatment.\n",
    "\n",
    "We can look at these extremes in more detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot positive errors/means\n",
    "tools.plot_threshold_errors(beta_estimates, beta_se, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot negative errors/means\n",
    "tools.plot_threshold_errors(beta_estimates, beta_se, 0.5, upper=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
